# train_fine_models.py
"""
ğŸ“¦ coarse ê·¸ë£¹ë³„ fine ì§ˆë³‘ ë¶„ë¥˜ ëª¨ë¸ í•™ìŠµ ìŠ¤í¬ë¦½íŠ¸
- coarse ê·¸ë£¹: ê°ê¸°, ê°ì—¼, ì†Œí™”ê¸°, í˜¸í¡ê¸°, ì‹¬í˜ˆê´€
- fine_config.json ê¸°ë°˜ìœ¼ë¡œ ê°œë³„ ëª¨ë¸ ì„¤ì • ë° í•™ìŠµ ì§„í–‰
"""

import json
import numpy as np
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder, StandardScaler, MultiLabelBinarizer
from sklearn.utils.class_weight import compute_class_weight
from sklearn.metrics import classification_report

from tensorflow.keras.models import Model
from tensorflow.keras.layers import Input, Dense, Dropout, Concatenate
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.callbacks import EarlyStopping
from tensorflow.keras.utils import to_categorical
from focal_loss import SparseCategoricalFocalLoss
import joblib
import os

# âœ… ê²½ë¡œ ì„¤ì •
CSV_PATH = "./data/raw/leaned_train_dataset.csv"
SBERT_PATH = "./data/processed/leaned_sbert_text_features_final.npy"
CONFIG_PATH = "./data/fine_config.json"
SAVE_DIR = "./models/fine"
os.makedirs(SAVE_DIR, exist_ok=True)

# âœ… í•œê¸€ ê·¸ë£¹ëª…ì„ ì˜ë¬¸ íŒŒì¼ëª…ìœ¼ë¡œ ë§¤í•‘
GROUP_NAME_MAP = {
    "ê°ê¸°": "cold",
    "ê°ì—¼": "infection",
    "ì†Œí™”ê¸°": "digestive",
    "í˜¸í¡ê¸°": "respiratory",
    "ì‹¬í˜ˆê´€": "cardio"
}

# âœ… ë°ì´í„° ë¡œë”© ë° ì „ì²˜ë¦¬
df = pd.read_csv(CSV_PATH, encoding="utf-8-sig")
df["disease_name"] = df["disease_name"].apply(lambda x: x[0] if isinstance(x, list) else x)
sbert_features = np.load(SBERT_PATH)[:len(df)]

# coarse ë¼ë²¨
coarse_map = {
    "ê°ê¸°": ["ê¸‰ì„± ê¸°ê´€ì§€ì—¼", "ê¸‰ì„± ë¹„ì¸ë‘ì—¼", "ê¸‰ì„± ì¸ë‘ì—¼", "ìƒê¸°ë„ ê°ì—¼"],
    "ê°ì—¼": ["ê¸‰ì„± ì¥ì—¼", "ê°„ì—¼", "ìš”ë¡œê°ì—¼"],
    "ì†Œí™”ê¸°": ["ìœ„ì—¼", "ìœ„ì‹ë„ì—­ë¥˜ì§ˆí™˜(GERD)", "ì†Œí™”ì„± ê¶¤ì–‘", "ì·Œì¥ì—¼", "ê³¼ë¯¼ì„± ëŒ€ì¥ì¦í›„êµ°"],
    "í˜¸í¡ê¸°": ["íë ´", "ì²œì‹", "ë§Œì„± íì‡„ì„± íì§ˆí™˜(COPD)"],
    "ì‹¬í˜ˆê´€": ["ì‹¬ë¶€ì „", "í˜‘ì‹¬ì¦", "ë¹ˆí˜ˆ"]
}

def map_coarse(name):
    for k, v in coarse_map.items():
        if name in v:
            return k
    return None

df["coarse_label"] = df["disease_name"].apply(map_coarse)
df.dropna(subset=["coarse_label"], inplace=True)
df.reset_index(drop=True, inplace=True)

# ìˆ˜ì¹˜ + ë²”ì£¼í˜• ì „ì²˜ë¦¬
numeric_cols = ["Age", "Height_cm", "Weight_kg", "BMI"]
df[numeric_cols] = StandardScaler().fit_transform(df[numeric_cols])
df["chronic_diseases"] = df["chronic_diseases"].apply(lambda x: x.split(',') if isinstance(x, str) and x != "ì—†ìŒ" else [])
df["medications"] = df["medications"].apply(lambda x: x.split(',') if isinstance(x, str) and x != "ì—†ìŒ" else [])
gender = df["Gender"].map({"ë‚¨ì„±": 1, "ì—¬ì„±": 0}).fillna(0).values.reshape(-1, 1)
mlb_chronic = MultiLabelBinarizer()
mlb_meds = MultiLabelBinarizer()
X_mlp = np.concatenate([
    df[numeric_cols].values,
    gender,
    mlb_chronic.fit_transform(df["chronic_diseases"]),
    mlb_meds.fit_transform(df["medications"])
], axis=1)
X_text = sbert_features.astype(np.float32)

# config ë¡œë”©
with open(CONFIG_PATH, "r", encoding="utf-8") as f:
    fine_config = json.load(f)

loss_map = {
    "categorical_crossentropy": "categorical_crossentropy",
    "focal": SparseCategoricalFocalLoss(gamma=2.0)
}

# ğŸ” coarse ê·¸ë£¹ë³„ ë°˜ë³µ í•™ìŠµ
fine_label_encoders = {}

for group in fine_config:
    config = fine_config[group]
    df_sub = df[df["coarse_label"] == group].copy()
    df_sub["fine_label"] = df_sub["disease_name"]

    label_encoder = LabelEncoder()
    df_sub["fine_encoded"] = label_encoder.fit_transform(df_sub["fine_label"])
    fine_label_encoders[group] = label_encoder

    y = to_categorical(df_sub["fine_encoded"]) if config["output_type"] == "onehot" else df_sub["fine_encoded"].values
    idx = df_sub.index
    X_mlp_group = X_mlp[idx]
    X_text_group = X_text[idx]

    X_train_mlp, X_val_mlp, X_train_text, X_val_text, y_train, y_val = train_test_split(
        X_mlp_group, X_text_group, y,
        test_size=0.15,
        stratify=df_sub["fine_encoded"],
        random_state=42
    )

    mlp_input = Input(shape=(X_train_mlp.shape[1],))
    x1 = Dense(64, activation='relu')(mlp_input)
    x1 = Dropout(0.2)(x1)

    text_input = Input(shape=(X_train_text.shape[1],))
    x2 = Dense(128, activation='relu')(text_input)
    x2 = Dropout(0.3)(x2)

    x = Concatenate()([x1, x2])
    x = Dense(128, activation='relu')(x)
    x = Dropout(0.3)(x)
    output = Dense(y.shape[1] if config["output_type"] == "onehot" else len(label_encoder.classes_), activation='softmax')(x)

    model = Model(inputs=[mlp_input, text_input], outputs=output)
    model.compile(
        optimizer=Adam(0.0005),
        loss=loss_map[config["loss"]],
        metrics=["accuracy"]
    )

    model.fit(
        [X_train_mlp, X_train_text], y_train,
        validation_data=([X_val_mlp, X_val_text], y_val),
        epochs=30,
        batch_size=64,
        callbacks=[EarlyStopping(patience=5, restore_best_weights=True)],
        verbose=1
    )

    y_pred = np.argmax(model.predict([X_val_mlp, X_val_text]), axis=1)
    y_true = np.argmax(y_val, axis=1) if config["output_type"] == "onehot" else y_val

    print(f"\nğŸ“Š {group} ê·¸ë£¹ fine ë¶„ë¥˜ ê²°ê³¼:")
    print(classification_report(y_true, y_pred, target_names=label_encoder.classes_))

    file_key = GROUP_NAME_MAP[group]  # âœ… ì˜ë¬¸ ì´ë¦„ ì‚¬ìš©
    model.save(f"{SAVE_DIR}/model_fine_{file_key}.h5")
    print(f"âœ… ëª¨ë¸ ì €ì¥ ì™„ë£Œ: model_fine_{file_key}.h5")

print("\nğŸ’¾ fine ì¸ì½”ë” ì €ì¥ ì¤‘...")
for group, encoder in fine_label_encoders.items():
    file_key = GROUP_NAME_MAP[group]
    joblib.dump(encoder, f"{SAVE_DIR}/fine_label_encoder_{file_key}.pkl")
    print(f"âœ… {group} â†’ ì €ì¥ ì™„ë£Œ: fine_label_encoder_{file_key}.pkl")
